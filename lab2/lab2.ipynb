{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Transfer Learning & Transformers: Comparison of Transformer Architecture to Other Neural Networks in Evaluation of Movie Reviews and Ratings\n",
    "\n",
    "Group Members:\n",
    "\n",
    "- Parker Brown\n",
    "\n",
    "- Suma Chackola\n",
    "\n",
    "- Chris Peters\n",
    "\n",
    "- Oliver Raney\n",
    "\n",
    "\n",
    "\n",
    "**The execution of this lab was performed collaboratively across 4 computers. Therefore, while the individual cells are not all shown with the direct execution results, the code presented in those cells was utilized to produce the results in this notebook.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#P1\">1.0 Introduction & Dataset Overview</a>\n",
    "* <a href=\"#P2\">2.0 Transfer Learning Foundational Model </a>\n",
    "* <a href=\"#P3\">3.0 Splitting the Data </a>\n",
    "* <a href=\"#P4\">4.0 Training a Model from Scratch </a>\n",
    "* <a href=\"#P5\">5.0 Training a Model by Transfer Learning from Foundational Model </a>\n",
    "* <a href=\"#P6\">6.0 Fine-Tuning the Model </a>\n",
    "* <a href=\"#P6\">7.0 Results: Comparing All Investigated Models </a>\n",
    "________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P1\"></a>\n",
    "## 1.0 Introduction & Dataset Overview\n",
    "#### Give an overview of the dataset you have chosen to use. What is the classification task. Is this multi-task? Explain. What is the feature data? Who collected the data? Why? When? Is the data multi-modal? What evaluation criteria will you be using and why? \n",
    "\n",
    "In this lab, we are performing classification on Movie Review text to associate the text of the review with an overall \"positivity\" rating of Positive, Neutral, or Negative. By reviewing the text as a whole instead of sets of words or phrases, we are evaluating a sequential text to classify it into a distinct category.  \n",
    "\n",
    "### Dataset Overview\n",
    "The dataset we are using for this analysis comes from an IEEE Open Access repository at the following source: \n",
    "- Data Source: https://ieee-dataport.org/open-access/imdb-movie-reviews-dataset\n",
    "\n",
    "The dataset compiles movie reviews from the Internet Movie Database (IMDb),  https://www.imdb.com/, and contains 1 million reviews from 1150 movies spread across 17 genres. In this dataset is other metadata such as the IMDb rating and movie rating. The data was compiled by Pal, Barigidad, and Mustafi and utilized and presented as a paper at the 2020 International Conference on Computing, Communication, and Security (ICCCS). In their analysis, they used the content of the movie reviews to classify the genre of the movie through word tokenization and a keyword list specific to the genre, and from their results they created a \"Movie Recommender\" based on a genre input from a user.\n",
    "\n",
    "This is not a multi-modal dataset because it only contains textual data. We did not choose a multi-modal dataset, although there are other IMDb datasets that do contain multi-modal data, such as this one: https://arxiv.org/abs/1702.01992, which contains images of the poster of the movie, in addition to the movie genre, rating, and other text. \n",
    "\n",
    "\n",
    "### Classification Task\n",
    "We utilized this dataset in Lab 1 for this course, where we performed sentiment analysis on the movie reviews and compared that sentiment to the movie positivity rating. For this lab, we differentiate that approach by using neural networks with a word embedding vectorizer to train a model. The training will analyze the sequential text in the review and use the associated rating to learn how the overall sequence relates to the positivity with respect to the vectorization of the sequence. Once that association is learned, the model evaluates new review sequences to classify those to an appropriate rating using the same vectorization analysis approach. \n",
    "\n",
    "In the dataset, the reviews are rated on a scale of 1-10. With our classifier, we will expect to get a similar scale, so that it is a multi-class classification task. We plan to segment the results into generalized score categories of:\n",
    "- Score < 3.5 -> \"Negative\"\n",
    "- 3.5 < Score < 6.5 -> \"Neutral\"\n",
    "- 6.5 < Score -> \"Positive\"\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P2\"></a>\n",
    "## 2.0 Transfer Learning Foundational Model\n",
    "#### Describe the foundational model that you will be using to transfer learn from. What tasks was this foundational model trained upon? Explain if the new task is within the same domain, across domains, etc. \n",
    "\n",
    "### Foundational Model: BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P3\"></a>\n",
    "## 3.0 Splitting the Data \n",
    "#### Split the data into training and testing. Be sure to explain how you performed this operation and why you think it is reasonable to split this particular dataset this way. For multi-task datasets, be sure to explain if it is appropriate to stratify within each task. If the dataset is already split for you, explain how the split was achieved and how it is stratified.\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpful</th>\n",
       "      <th>total</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imme-van-Gorp</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>123</td>\n",
       "      <td>30 January 2019</td>\n",
       "      <td>Unfortunately the ending ruined an otherwise ...</td>\n",
       "      <td>This movie is full of suspense. It makes you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sonofocelot-1</td>\n",
       "      <td>5</td>\n",
       "      <td>385</td>\n",
       "      <td>500</td>\n",
       "      <td>10 May 2016</td>\n",
       "      <td>...oh dear Abrams. Again.\\n</td>\n",
       "      <td>I'll leave this review fairly concise. &lt;br/&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mhodaee</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>143</td>\n",
       "      <td>4 August 2017</td>\n",
       "      <td>Fantastic, gripping, thoroughly enjoyable, un...</td>\n",
       "      <td>I give the 5/10 out of the credit I owe to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fil-nik09</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>5 October 2016</td>\n",
       "      <td>Hmmm...\\n</td>\n",
       "      <td>First of all, I must say that I was expecting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVR_Brale</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>27 July 2016</td>\n",
       "      <td>Slow building &amp; plot alternating claustrophob...</td>\n",
       "      <td>I've always loved movies with strong atmospher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username rating  helpful  total             date  \\\n",
       "0  Imme-van-Gorp      7      102    123  30 January 2019   \n",
       "1  sonofocelot-1      5      385    500      10 May 2016   \n",
       "2        mhodaee      5      110    143    4 August 2017   \n",
       "3      fil-nik09      5       73    100   5 October 2016   \n",
       "4      DVR_Brale      7       42     56     27 July 2016   \n",
       "\n",
       "                                               title  \\\n",
       "0   Unfortunately the ending ruined an otherwise ...   \n",
       "1                        ...oh dear Abrams. Again.\\n   \n",
       "2   Fantastic, gripping, thoroughly enjoyable, un...   \n",
       "3                                          Hmmm...\\n   \n",
       "4   Slow building & plot alternating claustrophob...   \n",
       "\n",
       "                                              review  \n",
       "0  This movie is full of suspense. It makes you g...  \n",
       "1  I'll leave this review fairly concise. <br/><b...  \n",
       "2  I give the 5/10 out of the credit I owe to the...  \n",
       "3  First of all, I must say that I was expecting ...  \n",
       "4  I've always loved movies with strong atmospher...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "# and https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "\n",
    "\n",
    "\n",
    "directory = 'data/movie_dataset/2_reviews_per_movie_raw'\n",
    "\n",
    "dfs = list()\n",
    "\n",
    "#Concatenate data into one pandas dataframe\n",
    "for filename in os.listdir(directory):\t\n",
    "\tdata = pd.read_csv(os.path.join(directory, filename), header='infer')\t\n",
    "\tdfs.append(data)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '5', '9', '8', '10', 'Null', '6', '1', '4', '3', '2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only rating and review\n",
    "df = df.drop(columns=['username', 'helpful', 'total', 'date','title'], errors='ignore')\n",
    "\n",
    "#print unique ratings\n",
    "df.rating.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  5,  9,  8, 10,  6,  1,  4,  3,  2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop Null ratings\n",
    "df = df[~df['rating'].str.contains('Null')]\n",
    "\n",
    "# Convert \"rating\" to int\n",
    "df= df.astype({'rating':'int'})\n",
    "df.rating.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This movie is full of suspense. It makes you g...\n",
       "1    I'll leave this review fairly concise. <br/><b...\n",
       "2    I give the 5/10 out of the credit I owe to the...\n",
       "3    First of all, I must say that I was expecting ...\n",
       "4    I've always loved movies with strong atmospher...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop rows where \"rating\" is NaN or reviews are missing\n",
    "df = df.dropna(subset=['rating'])\n",
    "df = df.dropna(subset=['review'])\n",
    "\n",
    "\n",
    "df_ratings = df['rating']\n",
    "df_reviews = df['review']\n",
    "\n",
    "\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>this movie is full of suspense. it makes you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i'll leave this review fairly concise. &lt;br/&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>i give the 5/10 out of the credit i owe to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>first of all, i must say that i was expecting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>i've always loved movies with strong atmospher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0       7  this movie is full of suspense. it makes you g...\n",
       "1       5  i'll leave this review fairly concise. <br/><b...\n",
       "2       5  i give the 5/10 out of the credit i owe to the...\n",
       "3       5  first of all, i must say that i was expecting ...\n",
       "4       7  i've always loved movies with strong atmospher..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.lower() \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for train test split\n",
    "df_reviews_train, df_reviews_test,  df_ratings_train_, df_ratings_test = \\\n",
    "    train_test_split(df_reviews, df_ratings, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for train test split\n",
    "df_train, df_test = \\\n",
    "    train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P4\"></a>\n",
    "## 4.0 Training a Model from Scratch \n",
    "#### Train a model from scratch to perform the classification task (this does NOT need to be a transformer). That is, do not use transfer learning for the classification task. Verify the model converges (even if the model is overfit). This does NOT need to mirror the foundational model. This model may be far less computational to train.\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade keras-nlp\n",
    "#!pip install --upgrade keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"jax\" \n",
    "\n",
    "#import keras_nlp \n",
    "#import tensorflow\n",
    "#import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall keras keras-core keras-nlp\n",
    "#!pip install keras==2.15.0 keras-nlp==0.6.3\n",
    "\n",
    "#!pip install --upgrade keras-nlp\n",
    "#import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"jax\" or \"torch\"!\n",
    "\n",
    "#from keras import keras_nlp\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: I could pip install tensorflow but the following code is causing issues. I have added it to my PATH environment etc but its still a pain. See if you guys can get this to resolve.\n",
    "\n",
    "The reason I introduced this code was to see how to persist the history of the models. This was one of my tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36748\\4003007480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"multi_hot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmulti_hot_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmulti_hot_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmulti_hot_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "multi_hot_layer = keras.layers.TextVectorization(\n",
    "    max_tokens=4000, output_mode=\"multi_hot\"\n",
    ")\n",
    "multi_hot_layer.adapt(df_train.map(lambda x, y: x))\n",
    "\n",
    "multi_hot_ds = df_train.map(lambda x, y: multi_hot_layer(x), y)\n",
    "multi_hot_val_ds = df_test.map(lambda x, y: (multi_hot_layer(x), y))\n",
    "\n",
    "# We then learn a linear regression over that layer, and that's our entire\n",
    "# baseline model!\n",
    "\n",
    "inputs = keras.Input(shape=(4000,), dtype=\"int32\")\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "baseline_model = keras.Model(inputs, outputs)\n",
    "baseline_model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "baseline_model.fit(multi_hot_ds, validation_data=multi_hot_val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P5\"></a>\n",
    "## 5.0 Training a Model by Transfer Learning from Foundational Model \n",
    "#### Train a model by transfer learning from your foundational model. Verify that the new model converges. You only need to train a model using the bottleneck features for this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P6\"></a>\n",
    "## 6.0 Fine-Tuning the Model \n",
    "#### Perform fine tuning upon the model by training some layers within the foundational model. Verify that the model converges. \n",
    "xx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P7\"></a>\n",
    "## 7.0 Results: Comparing All Investigated Models \n",
    "#### Report the results of all models using the evaluation procedure that you argued for at the beginning of the lab. Compare the convergence of the models and the running time. Results should be reported with proper statistical comparisons and proper visualizations.\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
