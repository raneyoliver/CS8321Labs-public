{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Transfer Learning & Transformers: Comparison of Transformer Architecture to Other Neural Networks in Evaluation of Movie Reviews and Ratings\n",
    "\n",
    "Group Members:\n",
    "\n",
    "- Parker Brown\n",
    "\n",
    "- Suma Chackola\n",
    "\n",
    "- Chris Peters\n",
    "\n",
    "- Oliver Raney\n",
    "\n",
    "\n",
    "\n",
    "**The execution of this lab was performed collaboratively across 4 computers. Therefore, while the individual cells are not all shown with the direct execution results, the code presented in those cells was utilized to produce the results in this notebook.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#P1\">1.0 Introduction & Dataset Overview</a>\n",
    "* <a href=\"#P2\">2.0 Transfer Learning Foundational Model </a>\n",
    "* <a href=\"#P3\">3.0 Splitting the Data </a>\n",
    "* <a href=\"#P4\">4.0 Training a Model from Scratch </a>\n",
    "* <a href=\"#P5\">5.0 Training a Model by Transfer Learning from Foundational Model </a>\n",
    "* <a href=\"#P6\">6.0 Fine-Tuning the Model </a>\n",
    "* <a href=\"#P6\">7.0 Results: Comparing All Investigated Models </a>\n",
    "________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P1\"></a>\n",
    "## 1.0 Introduction & Dataset Overview\n",
    "#### Give an overview of the dataset you have chosen to use. What is the classification task. Is this multi-task? Explain. What is the feature data? Who collected the data? Why? When? Is the data multi-modal? What evaluation criteria will you be using and why? \n",
    "\n",
    "In this lab, we are performing classification on Movie Review text to associate the text of the review with an overall \"positivity\" rating of Positive, Neutral, or Negative. By reviewing the text as a whole instead of sets of words or phrases, we are evaluating a sequential text to classify it into a distinct category.  \n",
    "\n",
    "### Dataset Overview\n",
    "The dataset we are using for this analysis comes from an IEEE Open Access repository at the following source: \n",
    "- Data Source: https://ieee-dataport.org/open-access/imdb-movie-reviews-dataset\n",
    "\n",
    "The dataset compiles movie reviews from the Internet Movie Database (IMDb),  https://www.imdb.com/, and contains 1 million reviews from 1150 movies spread across 17 genres. In this dataset is other metadata such as the IMDb rating and movie rating. The data was compiled by Pal, Barigidad, and Mustafi and utilized and presented as a paper at the 2020 International Conference on Computing, Communication, and Security (ICCCS). In their analysis, they used the content of the movie reviews to classify the genre of the movie through word tokenization and a keyword list specific to the genre, and from their results they created a \"Movie Recommender\" based on a genre input from a user.\n",
    "\n",
    "This is not a multi-modal dataset because it only contains textual data. We did not choose a multi-modal dataset, although there are other IMDb datasets that do contain multi-modal data, such as this one: https://arxiv.org/abs/1702.01992, which contains images of the poster of the movie, in addition to the movie genre, rating, and other text. \n",
    "\n",
    "### Classification Task\n",
    "We utilized this dataset in Lab 1 for this course, where we performed sentiment analysis on the movie reviews and compared that sentiment to the movie positivity rating. For this lab, we differentiate that approach by using neural networks with a word embedding vectorizer to train a model. The training will analyze the sequential text in the review and use the associated rating to learn how the overall sequence relates to the positivity with respect to the vectorization of the sequence. Once that association is learned, the model evaluates new review sequences to classify those to an appropriate rating using the same vectorization analysis approach. \n",
    "\n",
    "In the dataset, the reviews are rated on a scale of 1-10. With our classifier, we will expect to get a similar scale, so that it is a multi-class classification task. We have considered whether to segment the results into generalized score categories of: Score < 3.5 -> \"Negative\" , - 3.5 < Score < 6.5 -> \"Neutral\" , - 6.5 < Score -> \"Positive\"\n",
    "However, we don't believe there is much utility in generalizing the results because it could mask the underlying performance of the models. \n",
    "\n",
    "### Evaluation Criteria\n",
    "We are considering a few aspects to evaluate throughout this analysis. First, we will evaluate the model as it is fitting by reviewing the performance of the accuracy and the loss on the training and test datasets so we can ensure the model is both converging and not overfitting. Further, we will consider the convergence time on each model to evaluate the model efficiency (with some allowance/forgiveness to the performance differences of the processors on each of our computers, since it is not guaranteed that the same computer is performing all of the evaluations).\n",
    "\n",
    "Once each model completes training, we will then utilize the F-score statistical testing as a metric to compare the performance of the models. F-score is an analysis of variance approach (ANOVA) that determines the statistical difference of two or more populations in hypothesis testing by comparing their variances. To do this, we divide the population sample variance between the groups by the variance within the groups to generate the F-score. If the F-score exceeds a certain value, then the null hypothesis can be rejected because the null hypothesis assumes that the variances are equal. If the F-score does not exceed this value, we cannot reject the null hypothesis because the evidence does not provide the conclusion that there is significant differnce in the variance. Source: https://www.geeksforgeeks.org/how-to-perform-an-f-test-in-python/\n",
    "\n",
    "In the case of this analysis, our null hypothesis is that the use of a transformer model, such as BERT, to analyze review text sequences to predict the overall rating will provide a more accurate classification performance than that of a traditional multi-layer perceptron. Further, we hypothesize that fine tuning BERT for our specific model will show an improved performance over BERT in its unchanged, transferred state.\n",
    "\n",
    "Because we're ultimately performing a classification task, we should consider not only the accuracy of the predcition, but we should consider the precision & the recall of the classification. For this task, we should consider both False Positives and False Negatives, with the assumption that the rating provided is the true rating for the movie. From a False Positive perspective, if a review provides a rating that is high whereas the rating is low, then the perception of the film is inverted, and a person may expect a masterpiece and instead experience an unsatisfying film. This would be a similar case for the False Negatives, where a review that reads with a low rating but actually has a high rating could lead to a person not experiencing an entertaining movie. Because either of these would defeat the purpose of the model, we should evaluate both Precision, which measures the model performance with respect to False Positives, and Recall, which measures the False Negative rate of the model. Therefore, we will look at maximizing the overall F1 score, which provides a weighted performance of both Precision & Recall so that it takes into account the performance of True Positives, True Negatives, False Positives, and False Negatives. \n",
    "We implement this approach using the following source: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P2\"></a>\n",
    "## 2.0 Transfer Learning Foundational Model\n",
    "#### Describe the foundational model that you will be using to transfer learn from. What tasks was this foundational model trained upon? Explain if the new task is within the same domain, across domains, etc. \n",
    "\n",
    "### Foundational Model: BERT\n",
    "In this analysis, we will perform transfer learning with the Bidrectional Encoder Representation (BERT) model (source: https://arxiv.org/abs/1810.04805). BERT was developed by Google for text sequences, and it provides an architecture that can be utilized for a variety of natural language processing tasks and is able to encode the context of statements in two directions, which ensures a greater understanding of the message in the text. BERT has a base version that includes 12 encoder layers with 12 heads per layer and 110M parameters, and it has a large version that includes 24 encoder layers with 16 heads per layer and 340M parameters.\n",
    "\n",
    "From the original paper, BERT performs bidirectional encoding by using a masked language model that randomly masks tokens in the input to predict the original vocabulary based only on context. The BERT framework can be utilized in two steps: pre-training & fine-tuning, where the model is trained on unlabled data and then fine-tuned with labeled data from downstream tasks. In the paper, the WordPiece embeddings (30k tokens, referenced in BERT paper above) were used to provide the foundational tokenization. For the pre-training, BERT used the BooksCorpus and English Wikipedia, which have 800M and 2500M words, respectively (all referenced in BERT paper above). From Wikipedia, only the text passages were utilized.\n",
    "\n",
    "Because BERT can be used for a variety of tasks and is text-based, we can say that it is within the same domain as the task we are performing. From its original paper, BERT was built for, among others, question-answering tasks, hypothesis-premise tasks, and sentiment analysis tasks. Our goal is effectively sentiment analysis, where we are evaluating the overall context of the review and to what extent a film was perceived as \"good\". \n",
    "\n",
    "### Fine-Tuning Approach\n",
    "One advantage of BERT is that it can be fine tuned for a given task. This fine-tuning is readily-available because BERT contains a self-attention mechanism that allows it to model many downstream tasks so that it can encode a concatenated text pair with bidirectional cross attention between two sentences. The fine-tuning tasks are relatively efficient processing-wise compared to the pre-training. One approach to performing this can be found in: https://classic.d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html.\n",
    "\n",
    "We will perform fine-tuning through...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P3\"></a>\n",
    "## 3.0 Splitting the Data \n",
    "#### Split the data into training and testing. Be sure to explain how you performed this operation and why you think it is reasonable to split this particular dataset this way. For multi-task datasets, be sure to explain if it is appropriate to stratify within each task. If the dataset is already split for you, explain how the split was achieved and how it is stratified.\n",
    "\n",
    "The dataset was compiled without regard to the distribution of the rating. In a plot below, we show that the data is heaviliy weighted towards positive reviews (with the majority ratings of 9 or 10). However, there is a substantial number of reviews for all cases. One question to ask is if it is important to maintain the distribution of the ratings, or if it is more important to provide a classifier that can perform equally well regardless of the rating. Because of the distribution, we have a few options for the data:\n",
    "1) Do no data augmentation & perform a random 80/20 split for Training & Test Data. From a positive perspective, this maintains all the data for evaluation, and the randomness should remove some bias in the results. Further, this is a straightforward splitting task. However, from a negative perspective, we expect bias in the results to remain and be pointed towards the positive entries.\n",
    "\n",
    "2) Keep an equal number of entries for each rating (Rating of 2 was the lowest quantity). From a positive perspective, this is very significant statistically and should provide satisfactory data. From a negative perspective, we may lose data quality from the diversity of the text provided for different rating values.\n",
    "\n",
    "3) Perform stratified shuffling & splitting. From a positive perspective, this is an improvement of option 1) in that new, \"unexpected\" bias, is not introduced through a random sampling. From a negative perspective, it still hold the bias towards the positive entries. However, one could argue that this bias towards a positive rating should be considered a \"feature\" of the data and perhaps means we should re-evaluate our \"upper limit\" for a \"Neutral\" rating. \n",
    "\n",
    "We ultimately decided to go with 2) above, where we removed many entries to keep the dataset with an even distribution. We ended with 5000 samples for each of the 10 ratings, which we believe is still statistically significant for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpful</th>\n",
       "      <th>total</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imme-van-Gorp</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>123</td>\n",
       "      <td>30 January 2019</td>\n",
       "      <td>Unfortunately the ending ruined an otherwise ...</td>\n",
       "      <td>This movie is full of suspense. It makes you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sonofocelot-1</td>\n",
       "      <td>5</td>\n",
       "      <td>385</td>\n",
       "      <td>500</td>\n",
       "      <td>10 May 2016</td>\n",
       "      <td>...oh dear Abrams. Again.\\n</td>\n",
       "      <td>I'll leave this review fairly concise. &lt;br/&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mhodaee</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>143</td>\n",
       "      <td>4 August 2017</td>\n",
       "      <td>Fantastic, gripping, thoroughly enjoyable, un...</td>\n",
       "      <td>I give the 5/10 out of the credit I owe to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fil-nik09</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>5 October 2016</td>\n",
       "      <td>Hmmm...\\n</td>\n",
       "      <td>First of all, I must say that I was expecting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DVR_Brale</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>27 July 2016</td>\n",
       "      <td>Slow building &amp; plot alternating claustrophob...</td>\n",
       "      <td>I've always loved movies with strong atmospher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username rating  helpful  total             date  \\\n",
       "0  Imme-van-Gorp      7      102    123  30 January 2019   \n",
       "1  sonofocelot-1      5      385    500      10 May 2016   \n",
       "2        mhodaee      5      110    143    4 August 2017   \n",
       "3      fil-nik09      5       73    100   5 October 2016   \n",
       "4      DVR_Brale      7       42     56     27 July 2016   \n",
       "\n",
       "                                               title  \\\n",
       "0   Unfortunately the ending ruined an otherwise ...   \n",
       "1                        ...oh dear Abrams. Again.\\n   \n",
       "2   Fantastic, gripping, thoroughly enjoyable, un...   \n",
       "3                                          Hmmm...\\n   \n",
       "4   Slow building & plot alternating claustrophob...   \n",
       "\n",
       "                                              review  \n",
       "0  This movie is full of suspense. It makes you g...  \n",
       "1  I'll leave this review fairly concise. <br/><b...  \n",
       "2  I give the 5/10 out of the credit I owe to the...  \n",
       "3  First of all, I must say that I was expecting ...  \n",
       "4  I've always loved movies with strong atmospher...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/how-to-iterate-over-files-in-directory-using-python/\n",
    "# and https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "\n",
    "\n",
    "\n",
    "directory = 'data/movie_dataset/2_reviews_per_movie_raw'\n",
    "\n",
    "dfs = list()\n",
    "\n",
    "#Concatenate data into one pandas dataframe\n",
    "for filename in os.listdir(directory):\t\n",
    "\tdata = pd.read_csv(os.path.join(directory, filename), header='infer')\t\n",
    "\tdfs.append(data)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '5', '9', '8', '10', 'Null', '6', '1', '4', '3', '2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only rating and review\n",
    "df = df.drop(columns=['username', 'helpful', 'total', 'date','title'], errors='ignore')\n",
    "\n",
    "#print unique ratings\n",
    "df.rating.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  5,  9,  8, 10,  6,  1,  4,  3,  2])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop Null ratings\n",
    "df = df[~df['rating'].str.contains('Null')]\n",
    "\n",
    "# Convert \"rating\" to int\n",
    "df= df.astype({'rating':'int'})\n",
    "df.rating.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>This movie is full of suspense. It makes you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I'll leave this review fairly concise. &lt;br/&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>I give the 5/10 out of the credit I owe to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>First of all, I must say that I was expecting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>I've always loved movies with strong atmospher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0       7  This movie is full of suspense. It makes you g...\n",
       "1       5  I'll leave this review fairly concise. <br/><b...\n",
       "2       5  I give the 5/10 out of the credit I owe to the...\n",
       "3       5  First of all, I must say that I was expecting ...\n",
       "4       7  I've always loved movies with strong atmospher..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop rows where \"rating\" is NaN or reviews are missing\n",
    "df = df.dropna(subset=['rating'])\n",
    "df = df.dropna(subset=['review'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>this movie is full of suspense. it makes you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>i'll leave this review fairly concise. &lt;br/&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>i give the 5/10 out of the credit i owe to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>first of all, i must say that i was expecting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>i've always loved movies with strong atmospher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0       7  this movie is full of suspense. it makes you g...\n",
       "1       5  i'll leave this review fairly concise. <br/><b...\n",
       "2       5  i give the 5/10 out of the credit i owe to the...\n",
       "3       5  first of all, i must say that i was expecting ...\n",
       "4       7  i've always loved movies with strong atmospher..."
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.lower() \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = df['rating'].hist(bins=10)\n",
    "plt.title('Histogram of Movie Rating Distribution') \n",
    "plt.xlabel('Movie Rating') \n",
    "plt.xlim(1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now trim down the dataset so that we have an equal distribution of all ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sample size: 50000\n",
      "1     5000\n",
      "2     5000\n",
      "3     5000\n",
      "4     5000\n",
      "5     5000\n",
      "6     5000\n",
      "7     5000\n",
      "8     5000\n",
      "9     5000\n",
      "10    5000\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_sample_size = 50000\n",
    "unique_ratings = df['rating'].nunique()\n",
    "samples_per_category = total_sample_size // unique_ratings  # Integer division to get samples per category\n",
    "\n",
    "if total_sample_size % unique_ratings != 0:\n",
    "    print(f\"Warning: {total_sample_size} is not evenly divisible by {unique_ratings} categories. \" +\n",
    "          f\"Actual total sample size will be {samples_per_category * unique_ratings}.\")\n",
    "\n",
    "# Uniformly sample rows from each rating category\n",
    "sampled_df = df.groupby('rating').apply(lambda x: x.sample(n=samples_per_category)).reset_index(drop=True)\n",
    "\n",
    "# Check the final sample size and distribution\n",
    "print(f\"Final sample size: {len(sampled_df)}\")\n",
    "print(sampled_df['rating'].value_counts())\n",
    "sampled_df.to_csv('sampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = sampled_df['rating'].hist(bins=10)\n",
    "plt.title('Histogram of Movie Rating Distribution') \n",
    "plt.xlabel('Movie Rating') \n",
    "plt.xlim(1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sampled_df = pd.read_csv('sampled_df.csv')\n",
    "sampled_df['review'] = sampled_df['review'].fillna('')\n",
    "sampled_df['review'] = sampled_df['review'].astype(str)\n",
    "\n",
    "# Clean up text per https://medium.com/@AMustafa4983/sentiment-analysis-on-imdb-movie-reviews-a-beginners-guide-d5136ec74e56\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    " \n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    # get rid of urls\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    # get rid of non words and extra spaces\n",
    "    text = re.sub('\\\\W', ' ', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('^ ', '', text)\n",
    "    text = re.sub(' $', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = word.translate(table)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = text.split()\n",
    "    filtered_sentence = ''\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        filtered_sentence = filtered_sentence + word + ' '\n",
    "    return filtered_sentence\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',',' , ')\n",
    "    text = text.replace('.',' . ')\n",
    "    text = text.replace('/',' / ')\n",
    "    text = text.replace('@',' @ ')\n",
    "    text = text.replace('#',' # ')\n",
    "    text = text.replace('?',' ? ')\n",
    "    text = normalize_text(text)\n",
    "    text = remove_punctuation(text)\n",
    "    #text = remove_stopwords(text)\n",
    "    #text = stemming(text)\n",
    "    return text\n",
    "\n",
    "Xt = [clean_text(text) for text in sampled_df['review'].tolist()]\n",
    "\n",
    "sampled_df.review = pd.DataFrame(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('sampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P4\"></a>\n",
    "## 4.0 Training a Model from Scratch \n",
    "#### Train a model from scratch to perform the classification task (this does NOT need to be a transformer). That is, do not use transfer learning for the classification task. Verify the model converges (even if the model is overfit). This does NOT need to mirror the foundational model. This model may be far less computational to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is it pretty to look at yes is it incredibly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>george clooney s movie good night and good luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bloated self absorbed cliche and unrealistic t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>how not to do it the thin red line quite simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>this movie was so awful the plot was all over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>this is absolutely sick this is the movie that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>i read the reviews and went with low expectati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "      <td>the first 28 days later was a surprise for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>edward norton stars as derek vinyard in americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>this is a truly beautiful movie amelie will ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                                             review\n",
       "0           0  is it pretty to look at yes is it incredibly b...\n",
       "1           0  george clooney s movie good night and good luc...\n",
       "2           0  bloated self absorbed cliche and unrealistic t...\n",
       "3           0  how not to do it the thin red line quite simpl...\n",
       "4           0  this movie was so awful the plot was all over ...\n",
       "...       ...                                                ...\n",
       "49995       1  this is absolutely sick this is the movie that...\n",
       "49996       1  i read the reviews and went with low expectati...\n",
       "49997       1  the first 28 days later was a surprise for the...\n",
       "49998       1  edward norton stars as derek vinyard in americ...\n",
       "49999       1  this is a truly beautiful movie amelie will ho...\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df = pd.read_csv('sampled_df.csv')\n",
    "\n",
    "sampled_df.rating.replace(to_replace = [1,2,3,4,5,6,7,8,9,10], \n",
    "               value = [0,0,0,0,0,\n",
    "                        1,1,1,1,1],\n",
    "                inplace=True)\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('sampled_df_bin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Model hyperparameters\n",
    "max_length = 100\n",
    "embedding_dim = 100\n",
    "num_filters = 128\n",
    "kernel_size = 5\n",
    "hidden_dims = 128\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts((sampled_df['review']).astype(str))\n",
    "vocab_size = len(tokenizer.word_index)+1  # Adding 1 to account for the reserved 0 index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences((sampled_df['review']).astype(str))\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(sequences, maxlen=max_length)\n",
    "y = sampled_df['rating'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, 100, 100)          8491800   \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 100, 128)          64128     \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 128)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,556,057\n",
      "Trainable params: 8,556,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, GlobalAveragePooling1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu', padding='same'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 71s 70ms/step - loss: 0.4771 - accuracy: 0.5020 - f1_m: 0.6637 - precision_m: 0.5020 - recall_m: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.4949 - val_f1_m: 0.6576 - val_precision_m: 0.4949 - val_recall_m: 1.0000\n",
      "Epoch 2/5\n",
      " 132/1000 [==>...........................] - ETA: 58s - loss: 0.3055 - accuracy: 0.5142 - f1_m: 0.6751 - precision_m: 0.5142 - recall_m: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21368\\1494716587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)  # Use 20% of the training data as validation data\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training took {elapsed_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.utils.plot_model(model, to_file='base_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history to a CSV file\n",
    "histdf_init = pd.DataFrame(history.history)\n",
    "histdf_init.to_csv('base_model_training_history2bin.csv', index=False)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1) \n",
    "results = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "results.to_csv('base_model_predictions2bin.csv', index=False)\n",
    "\n",
    "# Save the Keras model\n",
    "model.save('base_model2bin.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training performance converges, both from a loss and an accuracy perspective. The test dataset does not perform as well for this initial model. We will now evaluate this task using Transfer Learning to see if we have improvements in the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P5\"></a>\n",
    "## 5.0 Training a Model by Transfer Learning from Foundational Model \n",
    "#### Train a model by transfer learning from your foundational model. Verify that the new model converges. You only need to train a model using the bottleneck features for this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, TFDistilBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "max_length = 100\n",
    "batch_size = 125\n",
    "\n",
    "#sampled_df = pd.read_csv('sampled_df.csv')\n",
    "sampled_df = pd.read_csv('sampled_df_bin.csv')\n",
    "sampled_df['review'] = sampled_df['review'].fillna('')\n",
    "sampled_df['review'] = sampled_df['review'].astype(str)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "distil_bert = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def extract_features_in_batches(reviews, batch_size=25):\n",
    "    all_res = []\n",
    "    #all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch_reviews = reviews[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_reviews, padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")\n",
    "        outputs = distil_bert(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "        #embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # Extract embeddings\n",
    "        #all_embeddings.append(embeddings)\n",
    "        #results_seq = outputs.logits.numpy()\n",
    "        \n",
    "        results = outputs.logits[:,1]\n",
    "        all_res.append(results)\n",
    "    all_res = np.vstack(all_res)\n",
    "    \n",
    "   # all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(sampled_df['review'].tolist(), padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")\n",
    "#outputs = distil_bert(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "#results = outputs.logits[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tokenizer(sampled_df['review'][0], padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = distil_bert(input1['input_ids'], attention_mask=input1['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.00134485, -0.07536775]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_features_in_batches(sampled_df['review'].tolist(), batch_size)\n",
    "#X = results\n",
    "y = sampled_df['rating']  # Adjust ratings to start from 0\n",
    "X = X.reshape(50000)\n",
    "\n",
    "# Save the bottleneck features and labels\n",
    "np.save('bottleneck_embeddings.npy', X)\n",
    "np.save('ratings.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(50000)\n",
    "np.save('bottleneck_embeddings.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl = np.load('bottleneck_embeddings.npy')\n",
    "yl = np.load('ratings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xl.shape\n",
    "yl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 1)                 40001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,001\n",
      "Trainable params: 40,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = np.load('bottleneck_embeddings.npy')\n",
    "y = np.load('ratings.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xl, yl, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add\n",
    "#model.add(Dense(128, activation='relu', input_shape=(X_train.shape[0],)))\n",
    "#model.add(Dense(10, activation='softmax'))  # 10 rating classes\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(X_train.shape[0],)))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 40000) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40000), dtype=tf.float32, name='dense_46_input'), name='dense_46_input', description=\"created by layer 'dense_46_input'\"), but it was called on an input with incompatible shape (32,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_38\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_46\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer \"sequential_38\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(32,), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21368\\868282995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[0;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_38\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_46\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer \"sequential_38\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(32,), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)  # Use 20% of the training data as validation data\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training took {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P6\"></a>\n",
    "## 6.0 Fine-Tuning the Model \n",
    "#### Perform fine tuning upon the model by training some layers within the foundational model. Verify that the model converges. \n",
    "\n",
    "One approach to performing this can be found in: https://classic.d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load y and y_pred\n",
    "results = pd.read_csv('distilbert_model_predictions.csv')\n",
    "\n",
    "# Load the training history\n",
    "histdf = pd.read_csv('distilbert_model_training_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"P7\"></a>\n",
    "## 7.0 Results: Comparing All Investigated Models \n",
    "#### Report the results of all models using the evaluation procedure that you argued for at the beginning of the lab. Compare the convergence of the models and the running time. Results should be reported with proper statistical comparisons and proper visualizations.\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
